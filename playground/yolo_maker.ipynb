{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30626,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDp3Ym3VTClA",
        "outputId": "7287e227-93c2-4c46-f182-f6b4bd7c2ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> 1 - IOU(box, centroid)  metric should be used </h1>"
      ],
      "metadata": {
        "id": "cUdqvo6LSyg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchvision/\n",
        "\n",
        "import os\n",
        "from IPython.display import display as dis\n",
        "from IPython.display import Image as im\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import torch\n",
        "import time\n",
        "import torchvision\n",
        "\n",
        "\n",
        "from torchvision.ops import box_iou"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-02T09:07:51.764636Z",
          "iopub.execute_input": "2024-01-02T09:07:51.765043Z",
          "iopub.status.idle": "2024-01-02T09:08:05.223010Z",
          "shell.execute_reply.started": "2024-01-02T09:07:51.765023Z",
          "shell.execute_reply": "2024-01-02T09:08:05.221901Z"
        },
        "trusted": true,
        "id": "rPzTIwDxSyg1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copy(\"/content/drive/MyDrive/dataset_udacity/box_priors.json\", \"./\")\n",
        "shutil.copy(\"/content/drive/MyDrive/dataset_udacity/file_orderer.json\", \"./\")\n",
        "shutil.copy(\"/content/drive/MyDrive/dataset_udacity/data.yaml\", \"./\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "SOPphh_qV9Ku",
        "outputId": "04c5ffb4-c6a6-4668-a587-48f6d7680619"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/dataset_udacity/box_priors.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5539dfe8ee70>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/dataset_udacity/box_priors.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/dataset_udacity/file_orderer.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/dataset_udacity/data.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/dataset_udacity/box_priors.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from collections import OrderedDict\n",
        "\n",
        "\"\"\"\n",
        "- The custom yolo model is implemented as seen in the architecture diagrams\n",
        "- the parts , as in the diagram are:\n",
        "  1. backbone\n",
        "  2. neck\n",
        "  3-7. heads 1-5\n",
        "\n",
        "- head numbers are defined as in the architecture diagram\n",
        "\"\"\"\n",
        "\n",
        "class normed_Conv2d(nn.Conv2d):\n",
        "  def __init__(self,\n",
        "               do_norm = True,\n",
        "               act = \"silu\",\n",
        "               **kwargs):\n",
        "    super(normed_Conv2d, self).__init__(**kwargs)\n",
        "    self.normed = do_norm\n",
        "    self.norm_layer = nn.BatchNorm2d(num_features = self.out_channels)\n",
        "\n",
        "    if act == 'silu':\n",
        "      self.activation = nn.SiLU()\n",
        "\n",
        "    elif act =='relu':\n",
        "      self.activation = nn.ReLU()\n",
        "\n",
        "    # elif act == 'softmax':\n",
        "    #   self.activation = nn.\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = super(normed_Conv2d, self).forward(x)\n",
        "    if self.normed:\n",
        "      x = self.norm_layer(x)\n",
        "    x = self.activation(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" NN.SEQUENTIAL CAN BE USED INSTEAD OF MODULELIST, BUT IT TAKES THE SAME TIME AS LOOPING OVER LAYERS IN MODULELIST\n",
        "DEFINITION SHOULD BE DONE BY MAKING AN ORDEREDDICT OF THE LAYERS\"\"\"\n",
        "class bottleneck(nn.Module):\n",
        "  def __init__(self,\n",
        "               in_channels,\n",
        "               num_1x1_filters_per_rep,\n",
        "               num_3x3_filters_per_rep,\n",
        "               num_reps,\n",
        "               block_number = None,\n",
        "               downsample = False\n",
        "               ):\n",
        "    super(bottleneck, self).__init__()\n",
        "\n",
        "    self.num_1x1_filters_per_rep = num_1x1_filters_per_rep\n",
        "    self.num_3x3_filters_per_rep = num_3x3_filters_per_rep\n",
        "    self.num_reps = num_reps\n",
        "\n",
        "    layer_block = nn.ModuleList()\n",
        "\n",
        "    if block_number == None:\n",
        "        block_number = \"NA\"\n",
        "\n",
        "    if downsample:\n",
        "      padding_3x3 = 0\n",
        "    else:\n",
        "      padding_3x3 = 1\n",
        "\n",
        "    for rep_no in range(self.num_reps):\n",
        "\n",
        "      rep = OrderedDict()\n",
        "\n",
        "      rep[f\"block_{block_number}_rep_{rep_no}_ConvBNSiLU_1x1\"] = normed_Conv2d(\n",
        "          in_channels =  in_channels,\n",
        "          out_channels = self.num_1x1_filters_per_rep,\n",
        "          kernel_size = 1,\n",
        "          # padding = 0 #same\n",
        "          )\n",
        "\n",
        "      rep[f\"block_{block_number}_rep_{rep_no}_ConvBNSiLU_3x3\"] = normed_Conv2d(\n",
        "          in_channels = self.num_1x1_filters_per_rep,\n",
        "          out_channels = self.num_3x3_filters_per_rep,\n",
        "          kernel_size = 3,\n",
        "          padding = padding_3x3 # same\n",
        "          )\n",
        "\n",
        "      rep = nn.Sequential(rep)\n",
        "\n",
        "      layer_block.add_module(name = f\"block_{block_number}_rep_{rep_no}\",\n",
        "                             module = rep)\n",
        "\n",
        "      in_channels = self.num_3x3_filters_per_rep\n",
        "\n",
        "    self.layer_block = layer_block\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    init_layer = True\n",
        "    for layer in self.layer_block:\n",
        "      if init_layer:\n",
        "        x = layer(x)\n",
        "      else:\n",
        "        x = layer(x) + x\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "class backbone(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(backbone, self).__init__()\n",
        "\n",
        "    self.super_block = OrderedDict()\n",
        "\n",
        "    ############### INPUT LAYER ################\n",
        "    self.super_block[\"input_layer\"] = normed_Conv2d(\n",
        "        in_channels = 3,\n",
        "        out_channels = 32,\n",
        "        kernel_size = 3\n",
        "    )\n",
        "    ############################################\n",
        "\n",
        "    ######## FIRST CONV ONLY BOTTLENECK ########\n",
        "    self.super_block[\"ConvBNSiLU_0\"] = normed_Conv2d(\n",
        "        in_channels = 32,\n",
        "        out_channels = 32,\n",
        "        kernel_size = 3\n",
        "    )\n",
        "\n",
        "    self.super_block[\"ConvBSSiLU_1\"] = normed_Conv2d(\n",
        "        in_channels = 32,\n",
        "        out_channels = 64,\n",
        "        kernel_size = 3,\n",
        "        stride = 2,\n",
        "        padding = 1\n",
        "    )\n",
        "    ############################################\n",
        "\n",
        "    #SEQUENTIAL REPETITVE BOTTLENECK SEQUENCE ##\n",
        "\n",
        "    self.super_block[\"bottleneck_0\"] = bottleneck(\n",
        "        in_channels = 64,\n",
        "        num_1x1_filters_per_rep = 32,\n",
        "        num_3x3_filters_per_rep = 64,\n",
        "        num_reps = 2,\n",
        "        block_number = 0,\n",
        "        downsample = True,\n",
        "    )\n",
        "\n",
        "    self.super_block[\"ConvBSSiLU_2\"] = normed_Conv2d(\n",
        "        in_channels = 64,\n",
        "        out_channels = 128,\n",
        "        kernel_size = 3,\n",
        "        stride = 2,\n",
        "        padding = 1\n",
        "    )\n",
        "\n",
        "    self.super_block[\"bottleneck_1\"] = bottleneck(\n",
        "        in_channels = 128,\n",
        "        num_1x1_filters_per_rep = 64,\n",
        "        num_3x3_filters_per_rep = 128,\n",
        "        num_reps = 6,\n",
        "        block_number = 1,\n",
        "        downsample = True\n",
        "    )\n",
        "\n",
        "    self.super_block[\"ConvBNSiLU_3\"] = normed_Conv2d(\n",
        "        in_channels = 128,\n",
        "        out_channels = 256,\n",
        "        kernel_size = 3,\n",
        "        stride = 2,\n",
        "        padding = 1\n",
        "    )\n",
        "\n",
        "    self.super_block[\"bottleneck_2\"] = bottleneck(\n",
        "        in_channels = 256,\n",
        "        num_1x1_filters_per_rep = 128,\n",
        "        num_3x3_filters_per_rep = 256,\n",
        "        num_reps = 8,\n",
        "        block_number = 2,\n",
        "        downsample = True\n",
        "\n",
        "    )\n",
        "\n",
        "    self.super_block[\"ConvBNSiLU_4\"] = normed_Conv2d(\n",
        "        in_channels = 256,\n",
        "        out_channels = 512,\n",
        "        kernel_size = 3,\n",
        "        stride = 2,\n",
        "        padding = 1,\n",
        "    )\n",
        "\n",
        "    self.super_block[\"bottleneck_3\"] = bottleneck(\n",
        "        in_channels = 512,\n",
        "        num_1x1_filters_per_rep = 256,\n",
        "        num_3x3_filters_per_rep = 512,\n",
        "        num_reps = 8,\n",
        "        block_number = 3,\n",
        "        downsample = True\n",
        "    )\n",
        "    ##########################################\n",
        "\n",
        "    self.super_block = nn.Sequential(self.super_block)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.super_block(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class neck(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(neck, self).__init__()\n",
        "\n",
        "    self.layers = nn.ModuleDict()\n",
        "\n",
        "    self.layers.add_module( name = \"ConvBNSiLU_0\",\n",
        "                           module = normed_Conv2d(\n",
        "                               in_channels = 512,\n",
        "                               out_channels = 1024,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 2,\n",
        "                               padding = 1\n",
        "                           ))\n",
        "\n",
        "    self.layers.add_module( name = \"bottleneck_0\",\n",
        "                           module = bottleneck(\n",
        "                               in_channels = 1024,\n",
        "                               num_1x1_filters_per_rep = 512,\n",
        "                               num_3x3_filters_per_rep = 1024,\n",
        "                               num_reps = 4,\n",
        "                               block_number = 0\n",
        "                           ))\n",
        "\n",
        "    self.layers.add_module( name = \"ConvBNSiLU_1\",\n",
        "                           module = normed_Conv2d(\n",
        "                               in_channels = 1024,\n",
        "                               out_channels = 512,\n",
        "                               kernel_size = 3,\n",
        "                               stride = 2,\n",
        "                               padding = 1\n",
        "                           ))\n",
        "\n",
        "    self.layers.add_module( name = \"bottleneck_1\",\n",
        "                           module = bottleneck(\n",
        "                               in_channels = 512,\n",
        "                               num_1x1_filters_per_rep = 256,\n",
        "                               num_3x3_filters_per_rep = 512,\n",
        "                               num_reps = 4,\n",
        "                               block_number = 1\n",
        "                           ))\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.input = x\n",
        "    self.outputs = OrderedDict()\n",
        "    for name, layer in self.layers.items():\n",
        "      x = layer(x)\n",
        "      self.outputs[name] = x\n",
        "\n",
        "    return self.outputs.copy()\n",
        "\n",
        "class head_downsample(nn.Module):\n",
        "  def __init__(self,\n",
        "               in_channels):\n",
        "    super(head_downsample, self).__init__()\n",
        "\n",
        "    self.head = OrderedDict()\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "\n",
        "    self.head[\"bottleneck_0\"] = bottleneck(\n",
        "        in_channels = self.in_channels,\n",
        "        num_1x1_filters_per_rep = 256,\n",
        "        num_3x3_filters_per_rep = 512,\n",
        "        num_reps = 1\n",
        "    )\n",
        "\n",
        "    self.head[\"ConvBNSiLU_0\"] = normed_Conv2d(\n",
        "        do_norm = False,\n",
        "        in_channels = 512,\n",
        "        out_channels = 80,\n",
        "        kernel_size = 3,\n",
        "        stride = 2,\n",
        "        padding = 1\n",
        "    )\n",
        "\n",
        "    self.head = nn.Sequential(self.head)\n",
        "\n",
        "  def forward(self, x1, x2):\n",
        "    x = torch.concat([x1, x2], axis = 1)\n",
        "\n",
        "    x = self.head(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "class head_upsample(nn.Module):\n",
        "  def __init__(self,\n",
        "               in_channels):\n",
        "    super(head_upsample, self).__init__()\n",
        "\n",
        "    self.upsampler = nn.Upsample(\n",
        "        scale_factor = 2,\n",
        "        mode = \"nearest\",\n",
        "    )\n",
        "\n",
        "    self.in_channels = in_channels\n",
        "\n",
        "    self.head = normed_Conv2d(\n",
        "        do_norm = False,\n",
        "        in_channels = self.in_channels,\n",
        "        out_channels = 80,\n",
        "        kernel_size = 3,\n",
        "        stride = 2,\n",
        "        padding = 1\n",
        "    )\n",
        "\n",
        "  def forward(self, x1, x2):\n",
        "    x2  = self.upsampler(x2)\n",
        "\n",
        "    x = torch.concat([x1, x2], axis = 1)\n",
        "\n",
        "    x = self.head(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class head_3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(head_3, self).__init__()\n",
        "\n",
        "    self.head = normed_Conv2d(\n",
        "        do_norm = False,\n",
        "        in_channels = 512,\n",
        "        out_channels = 80,\n",
        "        kernel_size = 4,\n",
        "        # stride = 2,\n",
        "        # padding = 1\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.head(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class my_yolo(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(my_yolo, self).__init__()\n",
        "\n",
        "    self.backbone = backbone()\n",
        "\n",
        "    self.neck = neck()\n",
        "\n",
        "    self.heads = nn.ModuleDict()\n",
        "\n",
        "    self.heads.add_module(\n",
        "        name = \"head_1\",\n",
        "        module = head_downsample(\n",
        "            in_channels = 2048\n",
        "        )\n",
        "    )\n",
        "\n",
        "    self.heads.add_module(\n",
        "        name = \"head_2\",\n",
        "        module = head_downsample(\n",
        "            in_channels = 1024\n",
        "        )\n",
        "    )\n",
        "\n",
        "    self.heads.add_module(\n",
        "        name = \"head_3\",\n",
        "        module = head_3()\n",
        "    )\n",
        "\n",
        "    self.heads.add_module(\n",
        "        name = \"head_4\",\n",
        "        module = head_upsample(\n",
        "            in_channels = 1536\n",
        "        )\n",
        "    )\n",
        "\n",
        "    self.heads.add_module(\n",
        "        name = \"head_5\",\n",
        "        module = head_upsample(\n",
        "            in_channels = 1536\n",
        "        )\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    output_dict = OrderedDict()\n",
        "\n",
        "    x = self.backbone(x)\n",
        "\n",
        "    neck_outputs = self.neck(x)\n",
        "\n",
        "    y_pred1 = self.heads[\"head_1\"](\n",
        "        neck_outputs[\"ConvBNSiLU_0\"],\n",
        "        neck_outputs[\"bottleneck_0\"]\n",
        "    )\n",
        "\n",
        "    output_dict[\"head_1\"] = y_pred1\n",
        "\n",
        "    y_pred2 = self.heads[\"head_2\"](\n",
        "        neck_outputs[\"ConvBNSiLU_1\"],\n",
        "        neck_outputs[\"bottleneck_1\"]\n",
        "    )\n",
        "\n",
        "    output_dict[\"head_2\"] = y_pred2\n",
        "\n",
        "    y_pred3 = self.heads[\"head_3\"](\n",
        "        neck_outputs[\"bottleneck_1\"]\n",
        "    )\n",
        "\n",
        "    output_dict[\"head_3\"] = y_pred3\n",
        "\n",
        "    y_pred4 = self.heads[\"head_4\"](\n",
        "        neck_outputs[\"bottleneck_0\"],\n",
        "        neck_outputs[\"bottleneck_1\"]\n",
        "    )\n",
        "\n",
        "    output_dict[\"head_4\"] = y_pred4\n",
        "\n",
        "    y_pred5 = self.heads[\"head_5\"](\n",
        "        x,\n",
        "        neck_outputs[\"bottleneck_0\"]\n",
        "    )\n",
        "\n",
        "    output_dict[\"head_5\"] = y_pred5\n",
        "\n",
        "    return output_dict\n",
        "\n",
        "\n",
        "def print_model_size(model):\n",
        "  param_size = 0\n",
        "  for param in model.parameters():\n",
        "      param_size += param.nelement() * param.element_size()\n",
        "  buffer_size = 0\n",
        "  for buffer in model.buffers():\n",
        "      buffer_size += buffer.nelement() * buffer.element_size()\n",
        "\n",
        "  size_all_mb = (param_size + buffer_size) / 1024**2\n",
        "  print('model size: {:.3f}MB'.format(size_all_mb))\n"
      ],
      "metadata": {
        "id": "ZcrVe12rpEIo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import time\n",
        "\n",
        "a = my_yolo()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "a.to(device)\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "x = (a(torch.rand([8,3,700,700]).to(device)))\n",
        "\n",
        "for name, posits in x.items():\n",
        "  print(f\"output from {name} : {posits.shape}\")\n",
        "\n",
        "# print(f\"completed yolo : result : {x.shape}\")\n",
        "\n",
        "\n",
        "# print(f\"completed head : result : {x.shape}\")\n",
        "\n",
        "print(f\"time taken to do a forward pass of the model {time.time() - start}\")\n",
        "\n",
        "print_model_size(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4WtmhRXGlmd",
        "outputId": "5d7e3938-1acb-4617-8652-73466277e2e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output from head_1 : torch.Size([8, 80, 4, 4])\n",
            "output from head_2 : torch.Size([8, 80, 2, 2])\n",
            "output from head_3 : torch.Size([8, 80, 1, 1])\n",
            "output from head_4 : torch.Size([8, 80, 4, 4])\n",
            "output from head_5 : torch.Size([8, 80, 8, 8])\n",
            "time taken to do a forward pass of the model 34.94960045814514\n",
            "model size: 220.260MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uOU2xAW3xMQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wj0zFEJoGeD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "a = torch.rand([5])\n",
        "b = torch.tenso([1,0,1,1,0])\n",
        "b = nn.BCEWithLogitsLoss()\n",
        "b(a)[0,:,1,1].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "z7PiqZS5Q-Yi",
        "outputId": "58748913-c512-48bb-ccc5-ee802cfd85cf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'torch' has no attribute 'tenso'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-938d9206b761>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtenso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEwithLogitsLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1833\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module '{__name__}' has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'tenso'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> PLAYGROUD</H1>"
      ],
      "metadata": {
        "id": "6sdFq0gDuIle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "posits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZDjQrAMzHS4",
        "outputId": "90c2790f-0918-449c-ebed-da4b98aa9b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-2.2934e-02, -4.0528e-02, -9.7456e-04,  ...,  1.4914e-01,\n",
              "           -1.1385e-01,  7.9855e-02],\n",
              "          [-2.7889e-02, -1.1845e-01, -5.5526e-02,  ..., -1.8147e-02,\n",
              "            3.2890e-01,  1.7740e-03],\n",
              "          [-1.9822e-02,  2.1691e-03, -5.3155e-03,  ...,  1.4366e-01,\n",
              "           -4.6002e-02,  2.4464e-01],\n",
              "          ...,\n",
              "          [-7.2684e-02, -1.1873e-01, -4.1904e-02,  ..., -2.4458e-01,\n",
              "            3.9596e-01, -1.0869e-01],\n",
              "          [-2.8447e-02, -6.1854e-02, -1.1705e-01,  ...,  2.0631e-01,\n",
              "            1.3241e-01,  1.7696e-01],\n",
              "          [-8.4373e-03, -1.3683e-02, -6.6647e-02,  ...,  1.0852e-01,\n",
              "            2.0221e-01, -1.2794e-01]],\n",
              "\n",
              "         [[ 5.5899e-03,  4.0710e-03, -7.4751e-02,  ...,  1.8281e-02,\n",
              "            9.4268e-02, -7.5644e-02],\n",
              "          [ 1.4904e-02, -1.0786e-02,  3.2714e-03,  ..., -1.4564e-01,\n",
              "            7.9229e-02, -1.1551e-01],\n",
              "          [ 3.6557e-02,  5.6362e-02,  1.1511e-03,  ...,  7.0439e-02,\n",
              "           -2.7200e-01, -2.3747e-01],\n",
              "          ...,\n",
              "          [ 1.4507e-02,  4.4300e-02, -4.4976e-02,  ..., -2.1470e-01,\n",
              "           -9.3693e-02, -1.8526e-01],\n",
              "          [ 4.9748e-03,  1.7043e-02, -2.1678e-03,  ..., -2.2754e-01,\n",
              "           -2.2028e-01, -2.2054e-01],\n",
              "          [ 2.8697e-02,  5.4662e-02,  6.9448e-03,  ..., -6.7836e-02,\n",
              "           -1.1788e-01, -1.3955e-02]],\n",
              "\n",
              "         [[-5.3702e-03, -2.8631e-02,  4.5573e-02,  ..., -9.7343e-02,\n",
              "            2.5746e-01,  1.2762e-02],\n",
              "          [ 1.8556e-02, -1.7206e-02,  9.7470e-03,  ..., -1.6605e-01,\n",
              "           -2.7792e-01, -1.5214e-01],\n",
              "          [ 2.4784e-02, -8.4779e-03, -3.2219e-02,  ..., -1.8619e-01,\n",
              "           -2.5919e-01, -2.7808e-01],\n",
              "          ...,\n",
              "          [ 3.1879e-02, -1.4403e-02, -1.6874e-02,  ..., -1.3886e-01,\n",
              "           -2.5890e-01, -6.9656e-02],\n",
              "          [ 1.4849e-03, -1.5780e-03, -4.0728e-02,  ..., -7.4331e-02,\n",
              "           -4.1484e-02, -8.4031e-02],\n",
              "          [ 2.9704e-03, -5.5915e-04, -4.5161e-02,  ...,  2.1786e-01,\n",
              "           -7.8426e-02, -1.5196e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 7.2270e-03, -7.6379e-03,  3.1609e-02,  ..., -1.3101e-02,\n",
              "            7.6727e-02, -1.6099e-01],\n",
              "          [-2.6387e-02, -2.0610e-02, -9.5179e-02,  ...,  6.0452e-03,\n",
              "           -1.4662e-01,  2.0678e-01],\n",
              "          [-6.4029e-02, -7.0015e-02, -6.9786e-02,  ...,  4.4020e-01,\n",
              "            8.1470e-01, -4.9594e-02],\n",
              "          ...,\n",
              "          [-3.5460e-02, -4.5199e-02, -1.0699e-02,  ...,  1.8607e-01,\n",
              "            5.1692e-02,  1.5923e-01],\n",
              "          [-5.4410e-02, -6.2948e-02, -6.6102e-02,  ...,  5.9595e-02,\n",
              "           -1.3115e-02, -1.1008e-01],\n",
              "          [-5.2241e-02, -7.7718e-02, -3.6610e-03,  ..., -9.2381e-02,\n",
              "            2.8986e-01, -7.6343e-02]],\n",
              "\n",
              "         [[ 6.4460e-03,  2.5469e-02,  1.2037e-02,  ...,  5.9794e-02,\n",
              "           -4.3506e-02,  1.0528e-01],\n",
              "          [ 4.9056e-02,  1.0253e-01,  7.0404e-02,  ...,  2.5944e-01,\n",
              "            2.1282e-01,  1.0977e-01],\n",
              "          [ 6.4401e-02,  1.4821e-01,  3.9152e-02,  ..., -8.3279e-02,\n",
              "           -5.5874e-02, -1.7103e-01],\n",
              "          ...,\n",
              "          [ 1.0408e-01,  7.5888e-02,  9.1886e-02,  ..., -2.0016e-01,\n",
              "           -2.3088e-01, -2.6317e-01],\n",
              "          [ 9.9154e-02,  1.0441e-01,  1.1561e-01,  ...,  6.7579e-02,\n",
              "           -1.7709e-01, -9.7478e-02],\n",
              "          [ 6.1485e-02,  7.0517e-02,  6.0622e-02,  ..., -9.0986e-02,\n",
              "            1.3819e-01, -4.0909e-02]],\n",
              "\n",
              "         [[-5.0845e-02, -1.6957e-03,  3.0624e-02,  ...,  6.4723e-02,\n",
              "           -1.2003e-02,  3.0014e-01],\n",
              "          [-4.3436e-02, -3.0476e-03,  3.2678e-02,  ...,  4.9095e-02,\n",
              "            2.2901e-01,  6.1638e-02],\n",
              "          [-6.4649e-03,  9.4252e-02, -5.8980e-02,  ..., -5.0178e-02,\n",
              "           -1.8829e-01, -6.3713e-02],\n",
              "          ...,\n",
              "          [-9.0667e-03,  4.5473e-02,  9.6381e-02,  ...,  1.3375e-01,\n",
              "            8.8157e-01,  2.2492e-01],\n",
              "          [-1.6016e-02,  3.5542e-02, -1.3196e-02,  ...,  1.1247e-02,\n",
              "           -9.8667e-02, -6.5081e-04],\n",
              "          [-7.3454e-04,  1.3576e-02, -3.6031e-04,  ..., -4.4387e-02,\n",
              "           -5.1212e-02, -1.3835e-01]]]], device='cuda:0',\n",
              "       grad_fn=<SiluBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dim_calc(a, n1, n2, n3, n4, n5):\n",
        "  a-= (2*n1)\n",
        "  print(a)\n",
        "  a/=2\n",
        "  print(a)\n",
        "  a-= (2*n2)\n",
        "  print(a)\n",
        "  a/=2\n",
        "  print(a)\n",
        "  a-= (2*n3)\n",
        "  print(a)\n",
        "  a/=2\n",
        "  print(a)\n",
        "  a-= (2*n4)\n",
        "  print(a)\n",
        "  a/=2\n",
        "  print(a)\n",
        "  a-= (2*n5)\n",
        "  print(a)\n",
        "\n",
        "  return a\n",
        "\n",
        "\n",
        "def dim_del(x1,x2,x3,x4,x5):\n",
        "  dim = (2*x1) + (2**2 * x2) + (2**3 * x3) + (2**4 * x4) + (2**5 * x5)\n",
        "\n",
        "  return dim\n",
        "\n",
        "\n",
        "def find_in_dim(out_dim , n1, n2, n3, n4, n5):\n",
        "  out_dim += (2*n5)\n",
        "  out_dim *= 2\n",
        "  out_dim += (2*n4)\n",
        "  out_dim *= 2\n",
        "  out_dim += (2*n3)\n",
        "  out_dim *= 2\n",
        "  out_dim += (2*n2)\n",
        "  out_dim *= 2\n",
        "  out_dim += (2*n1)\n",
        "  print(f\"num_layer : {n1+n2+n3+n4+n5}\")\n",
        "  return out_dim"
      ],
      "metadata": {
        "id": "85oMirEoEI3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_in_dim(16, 2, 2, 6, 8, 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6jMT0XNOF7P",
        "outputId": "54281b7a-ae73-48e6-ea4e-378bacf32ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_layer : 26\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "700"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim_calc(700, 2, 2, 6, 8, 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7H0fpA1Dkx5",
        "outputId": "d262a226-21ca-486c-ee33-fe194a655bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "696\n",
            "348.0\n",
            "344.0\n",
            "172.0\n",
            "160.0\n",
            "80.0\n",
            "64.0\n",
            "32.0\n",
            "16.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.0"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.device(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM9Y0L8K33c7",
        "outputId": "9a48ded7-348f-432a-e3b8-73dae9d7f5a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "a = bottleneck(in_channels = 128,\n",
        "               num_1x1_filters_per_rep = 64,\n",
        "               num_3x3_filters_per_rep = 128,\n",
        "               num_reps = 6,\n",
        "               block_number = 0,\n",
        "               downsample = True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = torch.device(\"cpu\")\n",
        "\n",
        "a.to(device)\n",
        "\n",
        "start = time.time()\n",
        "result = a(torch.rand([5,128,172,172]).to(device))\n",
        "print(result.shape)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"device : {device} : time taken : {end - start}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGEjbF9g3aQT",
        "outputId": "ae25834a-590c-44b8-9aa0-f6b3316abe31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 128, 160, 160])\n",
            "device : cuda : time taken : 0.18221807479858398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtgLGXrM5WUo",
        "outputId": "c765f20b-32e7-455a-9691-a39573627f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SiluBackward0 at 0x7fb23ea53c70>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch import nn\n",
        "import torch\n",
        "\n",
        "b = nn.Conv2d(in_channels = 512,\n",
        "              out_channels = 1024,\n",
        "              kernel_size = 3,\n",
        "              # padding = 1,\n",
        "              # stride = 2\n",
        "              )\n",
        "# a(b(torch.rand([5,512,8,8]))).shape\n",
        "\n",
        "b(torch.rand([5,512, 15, 15])).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP878BQD_llU",
        "outputId": "bb7e6989-a869-4ab6-eaa7-70971e66f766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 1024, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = seq_conv_block_1_3(\n",
        "    in_channels = 100,\n",
        "    num_1x1_filters_per_rep = 32,\n",
        "    num_3x3_filters_per_rep = 64,\n",
        "    num_reps = 800,\n",
        "    block_number= 0\n",
        ")\n",
        "\n",
        "b = conv_block_1_3(\n",
        "    in_channels = 100,\n",
        "    num_1x1_filters_per_rep = 32,\n",
        "    num_3x3_filters_per_rep = 64,\n",
        "    num_reps = 800=00,\n",
        "    block_number = 0\n",
        ")\n",
        "\n",
        "len(tuple(a.get_submodule(\"layer_block\").named_children()))"
      ],
      "metadata": {
        "id": "EKatZCBT_oAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testmodule = conv_block_1_3(\n",
        "    in_channels = 10,\n",
        "    num_filters_1x1 = 32,\n",
        "    num_filters_3x3 = 64,\n",
        "    num_reps = 6,\n",
        "    block_number = 10\n",
        ")\n",
        "\n",
        "print(tuple(testmodule.get_submodule(\"layer_block\").named_children()))\n",
        "\n",
        "print(testmodule(torch.ones([1,10,8,10])).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAwp32K0xqO0",
        "outputId": "0e8c479a-8486-439b-d559-38eead6b2c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(('block_10_rep_0_conv_1x1', Conv2d(10, 32, kernel_size=(1, 1), stride=(1, 1), padding=same)), ('block_10_rep_0_conv_3x3', Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)), ('block_10_rep_1_conv_1x1', Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), padding=same)), ('block_10_rep_1_conv_3x3', Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)), ('block_10_rep_2_conv_1x1', Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), padding=same)), ('block_10_rep_2_conv_3x3', Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)), ('block_10_rep_3_conv_1x1', Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), padding=same)), ('block_10_rep_3_conv_3x3', Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)), ('block_10_rep_4_conv_1x1', Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), padding=same)), ('block_10_rep_4_conv_3x3', Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)), ('block_10_rep_5_conv_1x1', Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), padding=same)), ('block_10_rep_5_conv_3x3', Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)))\n",
            "torch.Size([1, 64, 8, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-EmR3NpymST",
        "outputId": "da355210-8418-4070-a983-f567a6755a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 10, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "a = nn.ModuleList()\n",
        "\n",
        "a.append(nn.Conv2d(10,10,3))\n",
        "a.append(nn.Linear(10,10))\n",
        "a.append(nn.Linear(10,10))\n",
        "a.append(nn.Linear(10,9))\n",
        "a.register_module(name = \"mr conv 1\",\n",
        "                  module = nn.Conv2d(12,10,3))\n",
        "a.register_module(name = \"mr conv 1\",\n",
        "                  module = nn.Conv2d(9,10,3))  #using the same name will overwrite the module\n",
        "a.register_module(name = \"mr conv 2\",\n",
        "                  module = nn.Conv2d(9,11,3))\n",
        "a.register_module(name = \"mr conv 2\",\n",
        "                  module = nn.Conv2d(9,10,3))\n",
        "\n",
        "a.append(nn.Conv2d(9,11,3))\n",
        "\n",
        "tuple(a.named_children())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-C-E5yZrKvN",
        "outputId": "de7b9fac-6458-4d03-c8c5-d2414a153e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('0', Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))),\n",
              " ('1', Linear(in_features=10, out_features=10, bias=True)),\n",
              " ('2', Linear(in_features=10, out_features=10, bias=True)),\n",
              " ('3', Linear(in_features=10, out_features=9, bias=True)),\n",
              " ('mr conv 1', Conv2d(9, 10, kernel_size=(3, 3), stride=(1, 1))),\n",
              " ('mr conv 2', Conv2d(9, 10, kernel_size=(3, 3), stride=(1, 1))),\n",
              " ('6', Conv2d(9, 11, kernel_size=(3, 3), stride=(1, 1))))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ]
}