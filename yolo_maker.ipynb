{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30626,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDp3Ym3VTClA",
        "outputId": "600708ae-953c-42cd-f058-634c7793f50c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> 1 - IOU(box, centroid)  metric should be used </h1>"
      ],
      "metadata": {
        "id": "cUdqvo6LSyg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision\n",
        "\n",
        "import os\n",
        "from IPython.display import display as dis\n",
        "from IPython.display import Image as im\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import torch\n",
        "\n",
        "\n",
        "from torchvision.ops import box_iou"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-02T09:07:51.764636Z",
          "iopub.execute_input": "2024-01-02T09:07:51.765043Z",
          "iopub.status.idle": "2024-01-02T09:08:05.223010Z",
          "shell.execute_reply.started": "2024-01-02T09:07:51.765023Z",
          "shell.execute_reply": "2024-01-02T09:08:05.221901Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPzTIwDxSyg1",
        "outputId": "4e8ff599-720f-4116-c614-d13ff34bf0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 5, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
            "    from pip._internal.build_env import get_runnable_pip\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n",
            "    from pip._internal.cli.spinners import open_spinner\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
            "    from pip._internal.utils.logging import get_indentation\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 29, in <module>\n",
            "    from pip._internal.utils.misc import ensure_dir\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/misc.py\", line 40, in <module>\n",
            "    from pip._vendor.tenacity import retry, stop_after_delay, wait_fixed\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/tenacity/__init__.py\", line 167, in <module>\n",
            "    class AttemptManager:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/tenacity/__init__.py\", line 180, in AttemptManager\n",
            "    traceback: t.Optional[\"types.TracebackType\"],\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 309, in inner\n",
            "    return cached(*args, **kwds)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 403, in __getitem__\n",
            "    return self._getitem(self, parameters)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 530, in Optional\n",
            "    return Union[arg, type(None)]\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 309, in inner\n",
            "    return cached(*args, **kwds)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 403, in __getitem__\n",
            "    return self._getitem(self, parameters)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 520, in Union\n",
            "    return _UnionGenericAlias(self, parameters, name=\"Optional\")\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 1019, in __init__\n",
            "    super().__init__(origin, inst=inst, name=name)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 950, in __init__\n",
            "    self.__origin__ = origin\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 987, in __setattr__\n",
            "    if _is_dunder(attr) or attr in {'_name', '_inst', '_nparams',\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 936, in _is_dunder\n",
            "    return attr.startswith('__') and attr.endswith('__')\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copy(\"/content/drive/MyDrive/dataset_udacity/box_priors.json\", \"./\")\n",
        "shutil.copy(\"/content/drive/MyDrive/dataset_udacity/file_orderer.json\", \"./\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SOPphh_qV9Ku",
        "outputId": "fbbeb90b-8682-421e-e114-d2beea54c2b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./file_orderer.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from collections import OrderedDict\n",
        "\n",
        "class normed_Conv2d(nn.Conv2d):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(normed_Conv2d, self).__init__(**kwargs)\n",
        "    self.norm_layer = nn.BatchNorm2d(num_features = self.out_channels)\n",
        "    self.activation = nn.SiLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = super(normed_Conv2d, self).forward(x)\n",
        "    x = self.norm_layer(x)\n",
        "    x = self.activation(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" NN.SEQUENTIAL CAN BE USED INSTEAD OF MODULELIST, BUT IT TAKES THE SAME TIME AS LOOPING OVER LAYERS IN MODULELIST\n",
        "DEFINITION SHOULD BE DONE BY MAKING AN ORDEREDDICT OF THE LAYERS\"\"\"\n",
        "class bottleneck(nn.Module):\n",
        "  def __init__(self,\n",
        "               in_channels,\n",
        "               num_1x1_filters_per_rep,\n",
        "               num_3x3_filters_per_rep,\n",
        "               num_reps,\n",
        "               block_number = None,\n",
        "               downsample = False\n",
        "               ):\n",
        "    super(bottleneck, self).__init__()\n",
        "\n",
        "    self.num_1x1_filters_per_rep = num_1x1_filters_per_rep\n",
        "    self.num_3x3_filters_per_rep = num_3x3_filters_per_rep\n",
        "    self.num_reps = num_reps\n",
        "\n",
        "    layer_block = nn.ModuleList()\n",
        "\n",
        "    if block_number == None:\n",
        "        block_number = \"NA\"\n",
        "\n",
        "    if downsample:\n",
        "      padding_3x3 = 0\n",
        "    else:\n",
        "      padding_3x3 = 1\n",
        "\n",
        "    for rep_no in range(self.num_reps):\n",
        "\n",
        "      rep = OrderedDict()\n",
        "\n",
        "      rep[f\"block_{block_number}_rep_{rep_no}_ConvBNSiLU_1x1\"] = normed_Conv2d(\n",
        "          in_channels =  in_channels,\n",
        "          out_channels = self.num_1x1_filters_per_rep,\n",
        "          kernel_size = 1,\n",
        "          # padding = 0 #same\n",
        "          )\n",
        "\n",
        "      rep[f\"block_{block_number}_rep_{rep_no}_ConvBNSiLU_3x3\"] = normed_Conv2d(\n",
        "          in_channels = self.num_1x1_filters_per_rep,\n",
        "          out_channels = self.num_3x3_filters_per_rep,\n",
        "          kernel_size = 3,\n",
        "          padding = padding_3x3 # same\n",
        "          )\n",
        "\n",
        "      rep = nn.Sequential(rep)\n",
        "\n",
        "      layer_block.add_module(name = f\"block_{block_number}_rep_{rep_no}\",\n",
        "                             module = rep)\n",
        "\n",
        "      in_channels = self.num_3x3_filters_per_rep\n",
        "\n",
        "    self.layer_block = layer_block\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    init_layer = True\n",
        "    for layer in self.layer_block:\n",
        "      if init_layer:\n",
        "        x = layer(x)\n",
        "      else:\n",
        "        x = layer(x) + x\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "class backbone(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(backbone, self).__init__()\n",
        "\n",
        "    self.super_block = OrderedDict()\n",
        "\n",
        "    ############### INPUT LAYER ################\n",
        "    self.super_block[\"input_layer\"] = normed_Conv2d(\n",
        "        in_channels = 3,\n",
        "        out_channels = 32,\n",
        "        kernel_size = 3\n",
        "    )\n",
        "    ############################################\n",
        "\n",
        "    ######## FIRST CONV ONLY BOTTLENECK ########\n",
        "    self.super_block[\"ConvBNSiLU_1\"] = normed_Conv2d(\n",
        "        in_channels = 32,\n",
        "        out_channels = 32,\n",
        "        kernel_size = 3\n",
        "    )\n",
        "\n",
        "    self.super_block[\"ConvBSSiLU_2\"] = normed_Conv2d(\n",
        "        in_channels = 32,\n",
        "        out_channels = 64,\n",
        "        kernel_size = 3,\n",
        "        stride = 2,\n",
        "        padding = 1\n",
        "    )\n",
        "    ############################################\n",
        "\n",
        "    #SEQUENTIAL REPETITVE BOTTLENECK SEQUENCE ##\n",
        "\n",
        "    self.super_block[\"bottleneck_1\"] = bottleneck(\n",
        "        in_channels = 64,\n",
        "        num_1x1_filters_per_rep = 32,\n",
        "        num_3x3_filters_per_rep = 64,\n",
        "        num_reps = 2,\n",
        "        block_number = 0,\n",
        "        downsample = True,\n",
        "    )\n",
        "\n",
        "    self.super_block[\"ConvBSSiLU_3\"] = normed_Conv2d(\n",
        "        in_channels = 64,\n",
        "        out_channels = 128,\n",
        "        kernel_size = 3,\n",
        "        stride = 2,\n",
        "        padding = 1\n",
        "    )\n",
        "\n",
        "    self.super_block[\"bottleneck_2\"] = bottleneck(\n",
        "        in_channels = 128,\n",
        "        num_1x1_filters_per_rep = 64,\n",
        "        num_3x3_filters_per_rep = 128,\n",
        "        num_reps = 6,\n",
        "        block_number = 1,\n",
        "        downsample = True\n",
        "    )\n",
        "\n",
        "    self.super_block[\"ConvBNSiLU_4\"] = normed_Conv2d(\n",
        "        in_channels = 128,\n",
        "        out_channels = 256,\n",
        "        kernel_size = 3,\n",
        "        stride = 2,\n",
        "        padding = 1\n",
        "    )\n",
        "\n",
        "    self.super_block[\"bottleneck_3\"] = bottleneck(\n",
        "        in_channels = 256,\n",
        "        num_1x1_filters_per_rep = 128,\n",
        "        num_3x3_filters_per_rep = 256,\n",
        "        num_reps = 8,\n",
        "        block_number = 2,\n",
        "        downsample = True\n",
        "\n",
        "    )\n",
        "\n",
        "    self.super_block[\"ConvBNSiLU_5\"] = normed_Conv2d(\n",
        "        in_channels = 256,\n",
        "        out_channels = 512,\n",
        "        kernel_size = 3,\n",
        "        stride = 2,\n",
        "        padding = 1,\n",
        "    )\n",
        "\n",
        "    self.super_block[\"bottleneck_4\"] = bottleneck(\n",
        "        in_channels = 512,\n",
        "        num_3x3_filters_per_rep = 256,\n",
        "        num_1x1_filters_per_rep = 512,\n",
        "        num_reps = 8,\n",
        "        block_number = 3,\n",
        "        downsample = True\n",
        "    )\n",
        "    ##########################################\n",
        "\n",
        "    self.super_block = nn.Sequential(self.super_block)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.super_block(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZcrVe12rpEIo"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = bottleneck_block()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "a.to(device)\n",
        "start = time.time()\n",
        "print(a(torch.rand([1,3,700,700]).to(device)).shape)\n",
        "print(f\"time taken to do a forward pass of the bottlenxk {time.time() - start}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4WtmhRXGlmd",
        "outputId": "6618d771-a76c-4d8b-a5f7-b613f5fb02d1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 256, 16, 16])\n",
            "time taken to do a forward pass of the bottlenxk 0.17354655265808105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> PLAYGROUD</H1>"
      ],
      "metadata": {
        "id": "6sdFq0gDuIle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dim_calc(a, n1, n2, n3, n4, n5):\n",
        "  a-= (2*n1)\n",
        "  print(a)\n",
        "  a/=2\n",
        "  print(a)\n",
        "  a-= (2*n2)\n",
        "  print(a)\n",
        "  a/=2\n",
        "  print(a)\n",
        "  a-= (2*n3)\n",
        "  print(a)\n",
        "  a/=2\n",
        "  print(a)\n",
        "  a-= (2*n4)\n",
        "  print(a)\n",
        "  a/=2\n",
        "  print(a)\n",
        "  a-= (2*n5)\n",
        "  print(a)\n",
        "\n",
        "  return a\n",
        "\n",
        "\n",
        "def dim_del(x1,x2,x3,x4,x5):\n",
        "  dim = (2*x1) + (2**2 * x2) + (2**3 * x3) + (2**4 * x4) + (2**5 * x5)\n",
        "\n",
        "  return dim\n",
        "\n",
        "\n",
        "def find_in_dim(out_dim , n1, n2, n3, n4, n5):\n",
        "  out_dim += (2*n5)\n",
        "  out_dim *= 2\n",
        "  out_dim += (2*n4)\n",
        "  out_dim *= 2\n",
        "  out_dim += (2*n3)\n",
        "  out_dim *= 2\n",
        "  out_dim += (2*n2)\n",
        "  out_dim *= 2\n",
        "  out_dim += (2*n1)\n",
        "  print(f\"num_layer : {n1+n2+n3+n4+n5}\")\n",
        "  return out_dim"
      ],
      "metadata": {
        "id": "85oMirEoEI3D"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_in_dim(16, 2, 2, 6, 8, 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6jMT0XNOF7P",
        "outputId": "54281b7a-ae73-48e6-ea4e-378bacf32ebc"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_layer : 26\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "700"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim_calc(700, 2, 2, 6, 8, 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7H0fpA1Dkx5",
        "outputId": "d262a226-21ca-486c-ee33-fe194a655bbe"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "696\n",
            "348.0\n",
            "344.0\n",
            "172.0\n",
            "160.0\n",
            "80.0\n",
            "64.0\n",
            "32.0\n",
            "16.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.0"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.device(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM9Y0L8K33c7",
        "outputId": "9a48ded7-348f-432a-e3b8-73dae9d7f5a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "a = bottleneck(in_channels = 128,\n",
        "               num_1x1_filters_per_rep = 64,\n",
        "               num_3x3_filters_per_rep = 128,\n",
        "               num_reps = 6,\n",
        "               block_number = 0,\n",
        "               downsample = True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = torch.device(\"cpu\")\n",
        "\n",
        "a.to(device)\n",
        "\n",
        "start = time.time()\n",
        "result = a(torch.rand([5,128,172,172]).to(device))\n",
        "print(result.shape)\n",
        "end = time.time()\n",
        "\n",
        "print(f\"device : {device} : time taken : {end - start}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGEjbF9g3aQT",
        "outputId": "ae25834a-590c-44b8-9aa0-f6b3316abe31"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 128, 160, 160])\n",
            "device : cuda : time taken : 0.18221807479858398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtgLGXrM5WUo",
        "outputId": "c765f20b-32e7-455a-9691-a39573627f53"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SiluBackward0 at 0x7fb23ea53c70>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch import nn\n",
        "import torch\n",
        "\n",
        "b = nn.Conv2d(in_channels = 512,\n",
        "              out_channels = 1024,\n",
        "              kernel_size = 3,\n",
        "              # padding = 1,\n",
        "              # stride = 2\n",
        "              )\n",
        "# a(b(torch.rand([5,512,8,8]))).shape\n",
        "\n",
        "b(torch.rand([5,512, 15, 15])).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP878BQD_llU",
        "outputId": "bb7e6989-a869-4ab6-eaa7-70971e66f766"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 1024, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = seq_conv_block_1_3(\n",
        "    in_channels = 100,\n",
        "    num_1x1_filters_per_rep = 32,\n",
        "    num_3x3_filters_per_rep = 64,\n",
        "    num_reps = 800,\n",
        "    block_number= 0\n",
        ")\n",
        "\n",
        "b = conv_block_1_3(\n",
        "    in_channels = 100,\n",
        "    num_1x1_filters_per_rep = 32,\n",
        "    num_3x3_filters_per_rep = 64,\n",
        "    num_reps = 800=00,\n",
        "    block_number = 0\n",
        ")\n",
        "\n",
        "len(tuple(a.get_submodule(\"layer_block\").named_children()))"
      ],
      "metadata": {
        "id": "EKatZCBT_oAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testmodule = conv_block_1_3(\n",
        "    in_channels = 10,\n",
        "    num_filters_1x1 = 32,\n",
        "    num_filters_3x3 = 64,\n",
        "    num_reps = 6,\n",
        "    block_number = 10\n",
        ")\n",
        "\n",
        "print(tuple(testmodule.get_submodule(\"layer_block\").named_children()))\n",
        "\n",
        "print(testmodule(torch.ones([1,10,8,10])).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAwp32K0xqO0",
        "outputId": "0e8c479a-8486-439b-d559-38eead6b2c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(('block_10_rep_0_conv_1x1', Conv2d(10, 32, kernel_size=(1, 1), stride=(1, 1), padding=same)), ('block_10_rep_0_conv_3x3', Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)), ('block_10_rep_1_conv_1x1', Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), padding=same)), ('block_10_rep_1_conv_3x3', Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)), ('block_10_rep_2_conv_1x1', Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), padding=same)), ('block_10_rep_2_conv_3x3', Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)), ('block_10_rep_3_conv_1x1', Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), padding=same)), ('block_10_rep_3_conv_3x3', Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)), ('block_10_rep_4_conv_1x1', Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), padding=same)), ('block_10_rep_4_conv_3x3', Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)), ('block_10_rep_5_conv_1x1', Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), padding=same)), ('block_10_rep_5_conv_3x3', Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)))\n",
            "torch.Size([1, 64, 8, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-EmR3NpymST",
        "outputId": "da355210-8418-4070-a983-f567a6755a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 10, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "a = nn.ModuleList()\n",
        "\n",
        "a.append(nn.Conv2d(10,10,3))\n",
        "a.append(nn.Linear(10,10))\n",
        "a.append(nn.Linear(10,10))\n",
        "a.append(nn.Linear(10,9))\n",
        "a.register_module(name = \"mr conv 1\",\n",
        "                  module = nn.Conv2d(12,10,3))\n",
        "a.register_module(name = \"mr conv 1\",\n",
        "                  module = nn.Conv2d(9,10,3))  #using the same name will overwrite the module\n",
        "a.register_module(name = \"mr conv 2\",\n",
        "                  module = nn.Conv2d(9,11,3))\n",
        "a.register_module(name = \"mr conv 2\",\n",
        "                  module = nn.Conv2d(9,10,3))\n",
        "\n",
        "a.append(nn.Conv2d(9,11,3))\n",
        "\n",
        "tuple(a.named_children())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-C-E5yZrKvN",
        "outputId": "de7b9fac-6458-4d03-c8c5-d2414a153e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('0', Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))),\n",
              " ('1', Linear(in_features=10, out_features=10, bias=True)),\n",
              " ('2', Linear(in_features=10, out_features=10, bias=True)),\n",
              " ('3', Linear(in_features=10, out_features=9, bias=True)),\n",
              " ('mr conv 1', Conv2d(9, 10, kernel_size=(3, 3), stride=(1, 1))),\n",
              " ('mr conv 2', Conv2d(9, 10, kernel_size=(3, 3), stride=(1, 1))),\n",
              " ('6', Conv2d(9, 11, kernel_size=(3, 3), stride=(1, 1))))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ]
}